{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform and Load (ETL) Step\n",
    "\n",
    "We are going to use the YOLO algorithm for object detection. Let's transform the dataset into the format expected by YOLO\n",
    "\n",
    "https://docs.ultralytics.com/datasets/detect/#ultralytics-yolo-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import shutil\n",
    "\n",
    "\n",
    "ROOT_DIR = \"datasets\\\\aircraft\"\n",
    "LABELS_DIR = \"labels\"\n",
    "IMAGES_DIR = \"images\"\n",
    "TRAIN_DIR_LABELS = os.path.join(ROOT_DIR, LABELS_DIR, \"train\")\n",
    "VAL_DIR_LABELS = os.path.join(ROOT_DIR, LABELS_DIR, \"val\")\n",
    "TEST_DIR_LABELS = os.path.join(ROOT_DIR, LABELS_DIR, \"test\")\n",
    "TRAIN_DIR_IMAGES = os.path.join(ROOT_DIR, IMAGES_DIR, \"train\")\n",
    "VAL_DIR_IMAGES = os.path.join(ROOT_DIR, IMAGES_DIR, \"val\")\n",
    "TEST_DIR_IMAGES = os.path.join(ROOT_DIR, IMAGES_DIR, \"test\")\n",
    "DATASET_DIR = \"..\\\\dataset\\\\dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes Mapping\n",
    "\n",
    "We also need to provide a classes mapping, here is how we do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a10': 0, 'a400m': 1, 'ag600': 2, 'ah64': 3, 'av8b': 4, 'an124': 5, 'an22': 6, 'an225': 7, 'an72': 8, 'b1': 9, 'b2': 10, 'b21': 11, 'b52': 12, 'be200': 13, 'c130': 14, 'c17': 15, 'c2': 16, 'c390': 17, 'c5': 18, 'ch47': 19, 'cl415': 20, 'e2': 21, 'e7': 22, 'ef2000': 23, 'f117': 24, 'f14': 25, 'f15': 26, 'f16': 27, 'f22': 28, 'f35': 29, 'f4': 30, 'f18': 31, 'h6': 32, 'j10': 33, 'j20': 34, 'jas39': 35, 'jf17': 36, 'jh7': 37, 'kc135': 38, 'kf21': 39, 'kj600': 40, 'ka27': 41, 'ka52': 42, 'mq9': 43, 'mi24': 44, 'mi26': 45, 'mi28': 46, 'mig29': 47, 'mig31': 48, 'mirage2000': 49, 'p3': 50, 'rq4': 51, 'rafale': 52, 'sr71': 53, 'su24': 54, 'su25': 55, 'su34': 56, 'su57': 57, 'tb001': 58, 'tb2': 59, 'tornado': 60, 'tu160': 61, 'tu22m': 62, 'tu95': 63, 'u2': 64, 'uh60': 65, 'us2': 66, 'v22': 67, 'vulcan': 68, 'wz7': 69, 'xb70': 70, 'y20': 71, 'yf23': 72, 'z19': 73}\n"
     ]
    }
   ],
   "source": [
    "CLASSES_RAW = [\n",
    "    \"a10\",\n",
    "    \"a400m\",\n",
    "    \"ag600\",\n",
    "    \"ah64\",\n",
    "    \"av8b\",\n",
    "    \"an124\",\n",
    "    \"an22\",\n",
    "    \"an225\",\n",
    "    \"an72\",\n",
    "    \"b1\",\n",
    "    \"b2\",\n",
    "    \"b21\",\n",
    "    \"b52\",\n",
    "    \"be200\",\n",
    "    \"c130\",\n",
    "    \"c17\",\n",
    "    \"c2\",\n",
    "    \"c390\",\n",
    "    \"c5\",\n",
    "    \"ch47\",\n",
    "    \"cl415\",\n",
    "    \"e2\",\n",
    "    \"e7\",\n",
    "    \"ef2000\",\n",
    "    \"f117\",\n",
    "    \"f14\",\n",
    "    \"f15\",\n",
    "    \"f16\",\n",
    "    \"f22\",\n",
    "    \"f35\",\n",
    "    \"f4\",\n",
    "    # IN DATA AS F18\n",
    "    \"f18\",\n",
    "    \"h6\",\n",
    "    \"j10\",\n",
    "    \"j20\",\n",
    "    \"jas39\",\n",
    "    \"jf17\",\n",
    "    \"jh7\",\n",
    "    \"kc135\",\n",
    "    \"kf21\",\n",
    "    \"kj600\",\n",
    "    \"ka27\",\n",
    "    \"ka52\",\n",
    "    \"mq9\",\n",
    "    \"mi24\",\n",
    "    \"mi26\",\n",
    "    \"mi28\",\n",
    "    \"mig29\",\n",
    "    \"mig31\",\n",
    "    \"mirage2000\",\n",
    "    \"p3\",\n",
    "    \"rq4\",\n",
    "    \"rafale\",\n",
    "    \"sr71\",\n",
    "    \"su24\",\n",
    "    \"su25\",\n",
    "    \"su34\",\n",
    "    \"su57\",\n",
    "    \"tb001\",\n",
    "    \"tb2\",\n",
    "    \"tornado\",\n",
    "    \"tu160\",\n",
    "    \"tu22m\",\n",
    "    \"tu95\",\n",
    "    \"u2\",\n",
    "    \"uh60\",\n",
    "    \"us2\",\n",
    "    \"v22\",\n",
    "    \"vulcan\",\n",
    "    \"wz7\",\n",
    "    \"xb70\",\n",
    "    \"y20\",\n",
    "    \"yf23\",\n",
    "    \"z19\"\n",
    "]\n",
    "\n",
    "CLASSES = {model: i for i, model in enumerate(CLASSES_RAW)}\n",
    "\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming and Normalizing Bounding Boxes\n",
    "\n",
    "Since the dataset CSV is given using this format\n",
    "`filename, width, height, class, xmin, ymin, xmax, ymax`\n",
    "\n",
    "We need to turn it into a **normalized xywh format**, with the center point, bounding box width and height, all normalized to [0; 1]\n",
    "\n",
    "The normalize_bounding_box function does just that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.69580078125, 0.2490842490842491, 0.5595703125, 0.23882783882783884)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_bounding_box(\n",
    "    x_min: int, y_min: int, x_max: int, y_max: int, width: int, height: int\n",
    ") -> tuple[float, float, float, float]:\n",
    "    \"\"\"Generates normalized YOLO format xywh coordinates from bounding box pixel coordinates.\n",
    "\n",
    "    Args:\n",
    "        x_min (int): min x pixel from bounding box\n",
    "        y_min (int): min y pixel from bounding box\n",
    "        x_max (int): max x pixel from bounding box\n",
    "        y_max (int): max y pixel from bounding box\n",
    "        width (int): width of the image in pixels\n",
    "        height (int): height of the image in pixels\n",
    "\n",
    "    Returns:\n",
    "        x_center (float): x coordinates of the center of the bounding box [0; 1]\n",
    "        y_center (float): y coordinates of the center of the bounding box [0; 1]\n",
    "        width (float): width of the bounding box\n",
    "        height (float): height of the bounding box\n",
    "    \"\"\"\n",
    "\n",
    "    # First, we transform the min-max bounding box to center\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "\n",
    "    bb_width = x_max - x_min\n",
    "    bb_height = y_max - y_min\n",
    "\n",
    "    return (center_x / width, center_y / height, bb_width / width, bb_height / height)\n",
    "\n",
    "# Let's test it with a line in our dataset\n",
    "normalize_bounding_box(852, 177, 1998, 503, 2048, 1365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting and Transforming the Dataset\n",
    "\n",
    "We need to turn our dataset in the YOLO format, using a very specific directory structure.\n",
    "\n",
    "### Splitting the Dataset\n",
    "\n",
    "We need to split out dataset into three parts, train, validation and test.\n",
    "\n",
    "We're going to use (80%, 10%, 10%) repartition for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryType(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "    \n",
    "\n",
    "def split_dataset(seed: int = None) -> EntryType:\n",
    "    if not seed:\n",
    "        seed = time.time()\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    rand = random.randint(1, 10)\n",
    "\n",
    "    type = None\n",
    "\n",
    "    # Validation (10%)\n",
    "    if rand == 9:\n",
    "        type = EntryType.VAL\n",
    "\n",
    "    # Test (10%)\n",
    "    elif rand == 10:\n",
    "        type = EntryType.TEST\n",
    "\n",
    "    # Train (80%)\n",
    "    else:\n",
    "        type = EntryType.TRAIN\n",
    "\n",
    "    return type\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CSVEntry:\n",
    "    filename: str\n",
    "    img_width: int\n",
    "    img_height: int\n",
    "    airplane_class: str\n",
    "    x_min: int\n",
    "    y_min: int\n",
    "    x_max: int\n",
    "    y_max: int\n",
    "\n",
    "\n",
    "def process_csv_file(filename: str) -> list[CSVEntry]:\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    result = []\n",
    "\n",
    "    # Line 0 is for the column names\n",
    "    for line in lines[1:]:\n",
    "        entries = line.strip().split(\",\")\n",
    "        filename = entries[0]\n",
    "        img_width = int(entries[1])\n",
    "        img_height = int(entries[2])\n",
    "        airplane_class = entries[3]\n",
    "        x_min = int(entries[4])\n",
    "        y_min = int(entries[5])\n",
    "        x_max = int(entries[6])\n",
    "        y_max = int(entries[7])\n",
    "\n",
    "        result.append(\n",
    "        CSVEntry(\n",
    "            filename, img_width, img_height, airplane_class, x_min, y_min, x_max, y_max\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "def create_yolo_txt(entries: list[CSVEntry], type: str, filename: str) -> bool:\n",
    "    to_dir = \"\"\n",
    "\n",
    "    if type == EntryType.TRAIN:\n",
    "        to_dir = TRAIN_DIR_LABELS\n",
    "    \n",
    "    elif type == EntryType.VAL:\n",
    "        to_dir = VAL_DIR_LABELS\n",
    "\n",
    "    else:\n",
    "        to_dir = TEST_DIR_LABELS\n",
    "        \n",
    "\n",
    "    os.makedirs(to_dir, exist_ok=True)\n",
    "\n",
    "    fname_noext = Path(filename).stem\n",
    "\n",
    "    to_create = os.path.join(to_dir, fname_noext + \".txt\")\n",
    "\n",
    "\n",
    "    with open(to_create, \"w\") as f:\n",
    "        for entry in entries:\n",
    "            classid = CLASSES[entry.airplane_class.lower()]\n",
    "            x_center, y_center, width, height = normalize_bounding_box(entry.x_min, entry.y_min, entry.x_max, entry.y_max, entry.img_width, entry.img_height)\n",
    "            f.write(' '.join(map(str, [classid, x_center, y_center, width, height])) + '\\n')\n",
    "    \n",
    "    print(f\"Wrote {to_create}\")\n",
    "\n",
    "    return True\n",
    "\n",
    "def copy_image(type: str, filename: str) -> bool:\n",
    "\n",
    "    to_dir = \"\"\n",
    "\n",
    "    if type == EntryType.TRAIN:\n",
    "        to_dir = TRAIN_DIR_IMAGES\n",
    "    \n",
    "    elif type == EntryType.VAL:\n",
    "        to_dir = VAL_DIR_IMAGES\n",
    "\n",
    "    else:\n",
    "        to_dir = TEST_DIR_IMAGES\n",
    "\n",
    "    os.makedirs(to_dir, exist_ok=True)\n",
    "\n",
    "    to_copy = os.path.join(DATASET_DIR, filename + \".jpg\")\n",
    "\n",
    "    to_paste = os.path.join(to_dir, filename + \".jpg\")\n",
    "\n",
    "    shutil.copyfile(to_copy, to_paste)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def extract_transform_yolo(dataset_dir: str = DATASET_DIR, seed: int = None) -> None:\n",
    "    directory = os.fsencode(dataset_dir)\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        # Only process CSV files\n",
    "        if not filename.endswith(\"csv\"):\n",
    "            continue\n",
    "        \n",
    "        to_open = os.path.join(dataset_dir, filename)\n",
    "        entries = process_csv_file(to_open)\n",
    "\n",
    "        to_check = os.path.join(dataset_dir, entries[0].filename + \".jpg\")\n",
    "        if not os.path.exists(to_check):\n",
    "            print(\"File associated with CSV not found!\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "\n",
    "        # Determine where to add the entry (train, validation, test)\n",
    "        type = split_dataset()\n",
    "\n",
    "        if not create_yolo_txt(entries, type, filename):\n",
    "            print(f\"Error creating {filename} to {type}!\")\n",
    "\n",
    "        if not copy_image(type, entries[0].filename):\n",
    "             print(f\"Error copying {filename} to {type}!\")\n",
    "\n",
    "        \n",
    "        # time.sleep(1)\n",
    "\n",
    "    print(\"ETL done!\")\n",
    "\n",
    "# extract_transform_yolo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
